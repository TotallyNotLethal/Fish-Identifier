"""Simple augmentation pipeline that expands YOLO datasets using Albumentations.

The script mirrors the directory structure ``images/`` and ``labels/`` under
``data/processed/augmented``. Each input image receives color jitter and flip
variants, and mosaics are generated by combining four randomly selected images.

Usage example:
```
python data_processing/augment_dataset.py \
    --images-dir data/processed/images/train \
    --labels-dir data/processed/labels/train \
    --output-root data/processed/augmented \
    --augmentations-per-image 2
```
"""

from __future__ import annotations

import argparse
import math
import random
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Iterable, List, Sequence, Tuple

import albumentations as A
import numpy as np
from PIL import Image, ImageOps

YOLO_EXT = ".txt"


@dataclass
class Annotation:
    cls: int
    cx: float
    cy: float
    w: float
    h: float

    def as_tuple(self) -> Tuple[int, float, float, float, float]:
        return self.cls, self.cx, self.cy, self.w, self.h


def read_image(path: Path) -> np.ndarray:
    return np.array(Image.open(path).convert("RGB"))


def read_yolo_annotations(path: Path) -> List[Annotation]:
    if not path.exists():
        return []
    annotations = []
    for line in path.read_text(encoding="utf-8").strip().splitlines():
        if not line:
            continue
        parts = line.split()
        cls = int(parts[0])
        cx, cy, w, h = map(float, parts[1:5])
        annotations.append(Annotation(cls, cx, cy, w, h))
    return annotations


def save_yolo_annotations(path: Path, annotations: Iterable[Annotation]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    lines = ["{} {:.6f} {:.6f} {:.6f} {:.6f}".format(*ann.as_tuple()) for ann in annotations]
    path.write_text("\n".join(lines) + ("\n" if lines else ""), encoding="utf-8")


def build_transforms() -> A.Compose:
    return A.Compose(
        [
            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.8),
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.2),
        ],
        bbox_params=A.BboxParams(format="yolo", label_fields=["class_labels"]),
    )


def apply_transforms(image: np.ndarray, annotations: List[Annotation], transform: A.Compose) -> Tuple[np.ndarray, List[Annotation]]:
    bboxes = [ann.as_tuple()[1:] for ann in annotations]
    class_labels = [ann.cls for ann in annotations]
    result = transform(image=image, bboxes=bboxes, class_labels=class_labels)
    aug_annotations = [Annotation(cls, *bbox) for cls, bbox in zip(result["class_labels"], result["bboxes"])]
    return result["image"], aug_annotations


def save_augmented_example(image: np.ndarray, annotations: List[Annotation], *, output_images: Path, output_labels: Path, stem: str, suffix: str) -> None:
    output_image_path = output_images / f"{stem}_{suffix}.jpg"
    output_label_path = output_labels / f"{stem}_{suffix}{YOLO_EXT}"
    Image.fromarray(image).save(output_image_path, quality=95)
    save_yolo_annotations(output_label_path, annotations)


def create_mosaic(tile_paths: Sequence[Path], labels_dir: Path, size: int = 640) -> Tuple[np.ndarray, List[Annotation]]:
    tile_size = size // 2
    canvas = Image.new("RGB", (size, size))
    annotations: List[Annotation] = []
    offsets = [(0, 0), (tile_size, 0), (0, tile_size), (tile_size, tile_size)]

    for path, (offset_x, offset_y) in zip(tile_paths, offsets):
        image = ImageOps.fit(Image.open(path).convert("RGB"), (tile_size, tile_size))
        canvas.paste(image, (offset_x, offset_y))
        orig_width, orig_height = image.size
        label_path = labels_dir / f"{path.stem}{YOLO_EXT}"
        for ann in read_yolo_annotations(label_path):
            cx_px = ann.cx * orig_width + offset_x
            cy_px = ann.cy * orig_height + offset_y
            w_px = ann.w * orig_width
            h_px = ann.h * orig_height
            annotations.append(
                Annotation(
                    ann.cls,
                    cx_px / size,
                    cy_px / size,
                    w_px / size,
                    h_px / size,
                )
            )
    return np.array(canvas), annotations


def augment_dataset(images_dir: Path, labels_dir: Path, output_root: Path, *, augmentations_per_image: int = 1, seed: int = 42) -> None:
    random.seed(seed)
    images = sorted(p for p in images_dir.glob("*") if p.suffix.lower() in {".jpg", ".jpeg", ".png"})
    if not images:
        raise FileNotFoundError(f"No images found in {images_dir}")

    output_images = output_root / "images"
    output_labels = output_root / "labels"
    output_images.mkdir(parents=True, exist_ok=True)
    output_labels.mkdir(parents=True, exist_ok=True)

    transform = build_transforms()

    for image_path in images:
        image = read_image(image_path)
        annotations = read_yolo_annotations(labels_dir / f"{image_path.stem}{YOLO_EXT}")
        for idx in range(augmentations_per_image):
            augmented_image, augmented_annotations = apply_transforms(image, annotations, transform)
            save_augmented_example(
                augmented_image,
                augmented_annotations,
                output_images=output_images,
                output_labels=output_labels,
                stem=image_path.stem,
                suffix=f"aug{idx+1}",
            )

    # Generate mosaics from random image quartets.
    if len(images) >= 4:
        num_mosaics = max(1, math.ceil(len(images) / 4))
        for idx in range(num_mosaics):
            tiles = random.sample(images, 4)
            mosaic_image, mosaic_annotations = create_mosaic(tiles, labels_dir)
            save_augmented_example(
                mosaic_image,
                mosaic_annotations,
                output_images=output_images,
                output_labels=output_labels,
                stem=f"mosaic_{idx+1}",
                suffix="mix",
            )


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Augment a YOLO dataset using Albumentations")
    parser.add_argument("--images-dir", type=Path, required=True, help="Directory containing source images")
    parser.add_argument("--labels-dir", type=Path, required=True, help="Directory containing YOLO TXT annotations")
    parser.add_argument("--output-root", type=Path, default=Path("data/processed/augmented"), help="Where to save augmented samples")
    parser.add_argument("--augmentations-per-image", type=int, default=1, help="Number of augmented variants per image")
    parser.add_argument("--seed", type=int, default=42, help="Random seed for reproducibility")
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    augment_dataset(
        args.images_dir,
        args.labels_dir,
        args.output_root,
        augmentations_per_image=args.augmentations_per_image,
        seed=args.seed,
    )


if __name__ == "__main__":
    main()
